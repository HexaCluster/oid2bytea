#!/usr/bin/perl
#------------------------------------------------------------------------------
# Project  : This script is allow migration of large object column into bytea.
# Language : Perl
# Authors  : Gilles Darold, gilles _AT_ darold _DOT_ net
# Copyright: Copyright (c) 2025 : Gilles Darold - All rights reserved -
# Usage    : See oid2bytea --help
# Licence  : PostgreSQL
#------------------------------------------------------------------------------
use strict;

use Getopt::Long  qw(:config bundling no_ignore_case_always);
use POSIX qw(locale_h sys_wait_h _exit);
use Time::HiRes qw/usleep/;
use DBI;
use DBD::Pg;
use POSIX qw(strftime);

my $VERSION = '1.0';

# Command line options variables
my $DBNAME = '';
my $DBUSER = '';
my $DBHOST = '';
my $DBPORT = 5432;
my $VER    = 0;
my $HELP   = 0;
my $QUIET  = 0;
my $JOBS   = 1;
my $NOTIME = 0;
my $DRY_RUN    = 0;
my $NOVACUUMLO = 0;

my @INC_TABLES  = ();
my @INC_SCHEMAS = ();

my $interrupt    = 0;
my $child_count  = 0;
my %RUNNING_PIDS = ();
my $PG_OPT       = '';
my $dbh          = undef;

my $parent_pid = $$;

####
# Method used to fork as many child as wanted,
# must be declared at top if the program.
####
sub spawn
{
	my $coderef = shift;

	unless (@_ == 0 && $coderef && ref($coderef) eq 'CODE')
	{
		print "usage: spawn CODEREF";
		exit 0;
	}

	my $pid;
	if (!defined($pid = fork)) {
		print STDERR "Error: cannot fork: $!\n";
		return;
	} elsif ($pid) {
		$RUNNING_PIDS{$pid} = $pid;
		return; # the parent
	}
	# the child -- go spawn
	$< = $>;
	$( = $); # suid progs only

	exit &$coderef();
}

# Child reports error
sub child_error
{
	my $sig = shift;

	$interrupt = 1;

	print STDERR "An error occurs from a child process, aborting...\n";
	if ($^O !~ /MSWin32|dos/i) {
		1 while wait != -1;
		$SIG{INT} = \&wait_child;
		$SIG{TERM} = \&wait_child;
		$SIG{USR1} = \&child_error;
	}
	_exit(1);
}

# With multiprocess we need to wait for all children
sub wait_child
{
	my $sig = shift;

	$interrupt = 1;

	print STDERR "Received terminating signal ($sig)\n";
	if ($^O !~ /MSWin32|dos/i) {
		1 while wait != -1;
		$SIG{INT} = \&wait_child;
		$SIG{TERM} = \&wait_child;
	}
	$dbh->disconnect() if (defined $dbh);

	_exit(0);
}
$SIG{INT} = \&wait_child;
$SIG{TERM} = \&wait_child;
$SIG{USR1} = \&child_error;

$| = 1;

GetOptions(
	"d|database=s"       => \$DBNAME,
	"D|dry-run!"         => \$DRY_RUN,
	"h|host=s"           => \$DBHOST,
	"j|jobs=s"           => \$JOBS,
	"n|namespace=s"      => \@INC_SCHEMAS,
	"p|port=i"           => \$DBPORT,
	"q|quiet!"           => \$QUIET,
	"t|table=s"          => \@INC_TABLES,
	"u|user=s"           => \$DBUSER,
	"v|version!"         => \$VER,
	"V|no-vacuumlo!"     => \$NOVACUUMLO,
	"no-time!"           => \$NOTIME,
	"help!"              => \$HELP,
);

if ($VER)
{
	print "oid2bytea Version: v$VERSION\n";
	exit 0;
}

&usage if ($HELP);

# verify that vacuumlo is available in the path
if (!$NOVACUUMLO)
{
	my $vacuumlo_ver = `vacuumlo -V 2> /dev/null`;
	chomp($vacuumlo_ver);
	if (!$vacuumlo_ver) {
		die("Command vacuumlo must be installed and available from the PATH environment variable\n");
	}
}

if (!$DBNAME) {
        &usage("ERROR: you must specify a database, see -d option\n");
}

# Set PostgreSQL related options
if ($DBHOST) {
	$PG_OPT .= " -h $DBHOST";
}
if ($DBPORT) {
	$PG_OPT .= " -p $DBPORT";
}
if ($DBUSER) {
	$PG_OPT .= " -U $DBUSER";
}

# Set DBD::Pg options and connect to the database for testing
my $dbpg_opt = '';
$dbpg_opt .= ";port=$DBPORT" if ($DBPORT);
$dbpg_opt .= ";host=$DBHOST" if ($DBHOST);
$dbh = DBI->connect("dbi:Pg:application_name=oid2bytea;dbname=$DBNAME$dbpg_opt", $DBUSER, '', {AutoCommit => 1, InactiveDestroy => 1});
if (not defined $dbh) {
	logmsg('FATAL', "cannot connect to database $DBNAME");
}

# Look at PostgreSQL version
my $sth = $dbh->prepare("SELECT version()") or die "FATAL: " . $dbh->errstr . "\n";
$sth->execute or die "FATAL: " . $dbh->errstr . "\n";
my $pgversion = 0;
while (my $row = $sth->fetch)
{
	if ($row->[0] =~ /^[^\s]+ ([\.\d]+)/) {
		$pgversion = $1;
	}
}
$sth->finish;
logmsg('LOG', "Connection to PostgreSQL successfull");

logmsg('LOG', 'Starting conversion of large objects to bytea');

# Get oid columns to migrate
logmsg('LOG', 'Looking for large objects columns');
my $collist_query = "SELECT n.nspname, c.relname, a.attname FROM pg_attribute a JOIN pg_class c ON (a.attrelid=c.oid) JOIN pg_namespace n ON (c.relnamespace=n.oid) WHERE a.atttypid = 26 AND a.attnum > 0 AND n.nspname NOT IN ('pg_catalog', 'pg_toast', 'information_schema') AND NOT EXISTS (SELECT 1 FROM pg_catalog.pg_depend d WHERE d.refclassid = 'pg_catalog.pg_extension'::pg_catalog.regclass AND d.objid = c.oid AND d.deptype = 'e')";
if ($#INC_SCHEMAS < 0)
{
	$collist_query .= " AND n.nspname NOT IN ('pg_catalog', 'pg_toast', 'information_schema') AND NOT EXISTS (SELECT 1 FROM pg_catalog.pg_depend d WHERE d.refclassid = 'pg_catalog.pg_extension'::pg_catalog.regclass AND d.objid = c.oid AND d.deptype = 'e')";
}
else
{
	$collist_query .= "  AND n.nspname IN ('" . join("','", @INC_SCHEMAS) . "')";
}
#logmsg('LOG', "Using query: $collist_query");

$sth = $dbh->prepare($collist_query) or die "FATAL: " . $dbh->errstr . "\n";
$sth->execute or die "FATAL: " . $dbh->errstr . "\n";
my %collist = ();
while (my $row = $sth->fetch)
{
	logmsg('LOG', "Found oid column in table $row->[0].$row->[1] column $row->[2].");
	if ($#INC_TABLES < 0 || grep(/^$row->[1]$/, @INC_TABLES) || grep(/^$row->[0].$row->[1]$/, @INC_TABLES))
	{
		logmsg('LOG', "Registering column \"$row->[2]\" from table \"$row->[0].$row->[1]\" for migration.");
		push(@{ $collist{"$row->[0].$row->[1]"} }, $row->[2]);
	}
	else
	{
		logmsg('LOG', "Skiping, not in table list.");
	}
}
$sth->finish;

if (scalar keys %collist == 0) {
	logmsg('LOG', "No large object columns found.");
}

my $procnum = 0;
foreach my $tbname (sort keys %collist)
{
	spawn sub {
		logmsg('LOG', "Processing table $tbname...");
		transform_oid_to_bytea($procnum, $tbname, @{ $collist{$tbname} });
	};
	$procnum++;

	while ($procnum >= $JOBS)
	{
		my $kid = waitpid(-1, WNOHANG);
		if ($kid > 0)
		{
			$procnum--;
			delete $RUNNING_PIDS{$kid};
			last;
		}
		usleep(50000);
	}
}

# Then wait for all child processes to die
while (scalar keys %RUNNING_PIDS > 0)
{
        my $kid = waitpid(-1, WNOHANG);
        if ($kid > 0)
        {
                delete $RUNNING_PIDS{$kid};
        }
        usleep(50000);
}

# Now vacuum all orphan large object from the database
if (scalar keys %collist > 0)
{
	logmsg('LOG', "Running vacuumlo on the database to remove orphan large object");
	if ($DRY_RUN) {
		logmsg('LOG', "vacuumlo --dry-run$PG_OPT $DBNAME");
	} else {
		`vacuumlo $PG_OPT $DBNAME`;
	}
}

# Disconnect from snapshot connection
$dbh->disconnect;

exit(1) if ($interrupt);

logmsg('LOG', 'convertion ended');

exit 0;

#---------------------------------------------------------------------

####
# Show help about the program
####
sub usage
{
        my $msg = shift();

        print qq{
Program used to convert large objects columns in a PostgreSQL database into
bytea. The corresponding large objects data stored in the pg_largeobject table
will be moved into a newly created bytea column and the old oid column will be
removed. If no table list to convert is provided all columns with the oid data
type will be converted to bytea otherwise all oid columns of the table list
will be converted to bytea. 

	ALTER TABLE tb1 ADD COLUMN bytea_col bytea;
	UPDATE tb1 SET bytea_col = lo_get(lo_col);
	ALTER TABLE tb1 DROP COLUMN lo_col;
	ALTER TABLE tb1 rename column bytea_col TO lo_col;

Once all large objects are migrated the tool runs the vacuumlo command to
remove all orphan large objects from the datasase.

WARNING: the large object data will be duplicated until the `vacuumlo` command
is runu, be sure to have enough free space.

You may want to run a VACUUM FULL on modified tables to recover space from
the oid column(s).

Also take care in your application that the bytea column(s) are appended at end
of the table so their attribute position number change.


Usage: oid2bytea -d dbname [options]

options:

  -d, --database DBNAME        database where the migration job must be done.
  -D, --dry-run                do not do anything, just show what will be done.
  -h, --host HOSTNAME          database server host or socket directory.
  -j, --job NUM                use this many parallel jobs to process tables.
  -n, --namespace NAME         process tables created under the given schema.
                               Can be used multiple time.
  -p, --port PORT              database server port number, default: 5432.
  -q, --quiet                  don't display messages issued with the LOG level.
  -t, --table TABLE            migrate oid column(s) of the named relation. Can
                               be used multiple time.
  -u, --user NAME              connect as specified database user.
  -v, --version                show program version.
  -V, --no-vacuumlo            do not run vacuumlo at end to remove orphan
                               large objects.
  --help                       show usage.
  --no-time                    don't show timestamp in log output.

$msg
};
	exit 0;
}

####
# Return the date in ISO 8601 format minus the timezone part.
# As an example of returned value: 2019-09-03T09:03:12
####
sub get_current_date
{
    return strftime("%FT%T", localtime);
}

####
# Print a message with date/time and log level.
####
sub logmsg
{
	my ($level, $message) = @_;

	return if ($QUIET);

	if ($NOTIME) {
		print "$level: $message\n"
	} else {
		print '[' , get_current_date(), '] ', "$level: $message\n"
	}
}


sub transform_oid_to_bytea
{
	my ($proc, $tb, @colums) = @_;


	# Construct the SQL orders to execute
	my @alter1 = ();
	my @alter2 = ();
	my $update_sql = "UPDATE $tb SET ";
	for (my $c = 0; $c <= $#colums; $c++)
	{
	
		push(@alter1, "ALTER TABLE $tb ADD COLUMN bytea_col$c bytea");
		$update_sql .= "bytea_col$c = lo_get($colums[$c]), ";
		push(@alter2, "ALTER TABLE $tb DROP COLUMN $colums[$c]");
		push(@alter2, "ALTER TABLE $tb RENAME COLUMN bytea_col$c TO $colums[$c]");
	}
	$update_sql =~ s/, $//;

	# Add the bytea column(s)
	foreach my $q (@alter1)
	{
		logmsg('LOG', $q);
		if (!$DRY_RUN) {
			$dbh->do($q) or logmsg('ERROR', $dbh->errstr);
		}
	}

	# Migrate the large object into the bytea column(s)
	logmsg('LOG', $update_sql);
	if (!$DRY_RUN) {
		$dbh->do($update_sql) or logmsg('FATAL', $dbh->errstr);
	}

	# Drop the oid column(s) and rename the bytea column(s) with the old name of the old oid column(s)
	foreach my $q (@alter2)
	{
		logmsg('LOG', $q);
		if (!$DRY_RUN) {
			$dbh->do($q) or logmsg('ERROR', $dbh->errstr);
		}
	}
}
